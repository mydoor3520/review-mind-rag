"""ë¦¬ë·° ìš”ì•½ í˜ì´ì§€"""

import streamlit as st
from pathlib import Path
import sys
from typing import Any, Dict, List, Optional, Tuple

PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

st.set_page_config(
    page_title="ë¦¬ë·° ìš”ì•½ - Review Mind RAG",
    page_icon="ğŸ“Š",
    layout="wide"
)

st.title("ğŸ“Š ë¦¬ë·° ìš”ì•½")
st.markdown("ìƒí’ˆë³„ ë¦¬ë·°ë¥¼ ìë™ìœ¼ë¡œ ìš”ì•½í•˜ê³  ê°ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤.")


@st.cache_resource
def get_vectorstore():
    try:
        from src.rag.vectorstore import ReviewVectorStore
        return ReviewVectorStore(), None
    except Exception as e:
        return None, str(e)


@st.cache_resource
def get_summarizer():
    try:
        from src.analysis.summarizer import ReviewSummarizer
        return ReviewSummarizer(), None
    except Exception as e:
        return None, str(e)


@st.cache_resource
def get_sentiment_analyzer():
    try:
        from src.analysis.sentiment import SentimentAnalyzer
        return SentimentAnalyzer(), None
    except Exception as e:
        return None, str(e)


def search_product_reviews(
    product_id: str, k: int = 30
) -> Tuple[List[Any], Optional[str]]:
    vectorstore, error = get_vectorstore()
    if vectorstore is None:
        return [], error

    try:
        results = vectorstore.similarity_search(
            query=f"product {product_id}",
            k=k,
            filter={"product_id": product_id}
        )
        return results, None
    except Exception as e:
        return [], str(e)


def generate_summary(
    documents: List[Any]
) -> Tuple[Optional[Dict[str, Any]], Optional[str]]:
    summarizer, error = get_summarizer()
    if summarizer is None:
        return None, error

    try:
        result = summarizer.summarize(documents)
        return result, None
    except Exception as e:
        return None, str(e)


def extract_pros_cons(
    documents: List[Any]
) -> Tuple[Optional[Dict[str, List[str]]], Optional[str]]:
    summarizer, error = get_summarizer()
    if summarizer is None:
        return None, error

    try:
        result = summarizer.extract_pros_cons(documents)
        return result, None
    except Exception as e:
        return None, str(e)


def analyze_sentiment(
    documents: List[Any]
) -> Tuple[Optional[Dict[str, Any]], Optional[str]]:
    analyzer, error = get_sentiment_analyzer()
    if analyzer is None:
        return None, error

    try:
        result = analyzer.analyze_documents(documents)
        return result, None
    except Exception as e:
        return None, str(e)


with st.sidebar:
    st.markdown("### ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
    vectorstore, vs_error = get_vectorstore()
    summarizer, sum_error = get_summarizer()
    analyzer, an_error = get_sentiment_analyzer()

    if vectorstore:
        stats = vectorstore.get_collection_stats()
        st.success(f"âœ… VectorStore ({stats['document_count']:,} ë¦¬ë·°)")
    else:
        st.error(f"âŒ VectorStore: {vs_error}")

    if summarizer:
        st.success("âœ… Summarizer ì¤€ë¹„")
    else:
        st.error(f"âŒ Summarizer: {sum_error}")

    if analyzer:
        st.success("âœ… SentimentAnalyzer ì¤€ë¹„")
    else:
        st.error(f"âŒ Analyzer: {an_error}")

    st.markdown("---")
    st.markdown("### âš™ï¸ ì„¤ì •")
    max_reviews = st.slider("ë¶„ì„í•  ìµœëŒ€ ë¦¬ë·° ìˆ˜", min_value=10, max_value=50, value=30)

product_id = st.text_input("ìƒí’ˆ ID ì…ë ¥", placeholder="ASIN ë˜ëŠ” ìƒí’ˆ ID...")

if st.button("ğŸ“Š ìš”ì•½ ìƒì„±", type="primary"):
    if product_id:
        with st.spinner("ë¦¬ë·°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            documents, search_error = search_product_reviews(product_id, k=max_reviews)

            if search_error:
                st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {search_error}")
            elif not documents:
                st.warning(f"ìƒí’ˆ ID '{product_id}'ì— ëŒ€í•œ ë¦¬ë·°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.success(f"{len(documents)}ê°œì˜ ë¦¬ë·°ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("### âœ… ì¥ì  / âŒ ë‹¨ì ")
                    pros_cons, pc_error = extract_pros_cons(documents)

                    if pc_error:
                        st.error(f"ì¥ë‹¨ì  ì¶”ì¶œ ì˜¤ë¥˜: {pc_error}")
                    elif pros_cons:
                        pros_col, cons_col = st.columns(2)
                        with pros_col:
                            st.markdown("**âœ… ì¥ì **")
                            for pro in pros_cons.get("pros", []):
                                st.markdown(f"- {pro}")
                        with cons_col:
                            st.markdown("**âŒ ë‹¨ì **")
                            for con in pros_cons.get("cons", []):
                                st.markdown(f"- {con}")

                with col2:
                    st.markdown("### ğŸ“ˆ ê°ì„± ë¶„ì„")
                    sentiment_result, sent_error = analyze_sentiment(documents)

                    if sent_error:
                        st.error(f"ê°ì„± ë¶„ì„ ì˜¤ë¥˜: {sent_error}")
                    elif sentiment_result:
                        dist = sentiment_result["distribution"]

                        metric_col1, metric_col2, metric_col3 = st.columns(3)
                        with metric_col1:
                            st.metric("ğŸ˜Š ê¸ì •", f"{dist['positive']['percentage']}%")
                        with metric_col2:
                            st.metric("ğŸ˜ ì¤‘ë¦½", f"{dist['neutral']['percentage']}%")
                        with metric_col3:
                            st.metric("ğŸ˜ ë¶€ì •", f"{dist['negative']['percentage']}%")

                        avg_rating = sentiment_result['average_rating']
                        st.metric("â­ í‰ê·  í‰ì ", f"{avg_rating}ì ")

                st.markdown("---")
                st.markdown("### ğŸ“ ì¢…í•© ìš”ì•½")
                summary_result, sum_error = generate_summary(documents)

                if sum_error:
                    st.error(f"ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {sum_error}")
                elif summary_result:
                    st.markdown(summary_result["summary"])
                    review_count = summary_result['review_count']
                    total_count = summary_result.get('total_available', len(documents))
                    st.caption(f"ë¶„ì„ëœ ë¦¬ë·°: {review_count}ê°œ / ì´ {total_count}ê°œ")
    else:
        st.warning("ìƒí’ˆ IDë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

st.markdown("---")

with st.expander("ğŸ’¡ ì‚¬ìš© íŒ", expanded=False):
    st.markdown("""
    **ìƒí’ˆ ID ì°¾ê¸°:**
    - Search í˜ì´ì§€ì—ì„œ ê²€ìƒ‰ í›„ ìƒí’ˆ ID í™•ì¸
    - Amazon ASIN í˜•ì‹ (ì˜ˆ: B09V3KXJPB)

    **ë¶„ì„ ë‚´ìš©:**
    - **ì¥ë‹¨ì **: LLMì´ ë¦¬ë·°ì—ì„œ ì£¼ìš” ì¥ì ê³¼ ë‹¨ì ì„ ì¶”ì¶œ
    - **ê°ì„± ë¶„ì„**: í‰ì  ê¸°ë°˜ ê¸ì •/ì¤‘ë¦½/ë¶€ì • ë¹„ìœ¨ ê³„ì‚°
    - **ì¢…í•© ìš”ì•½**: ë¦¬ë·° ì „ì²´ë¥¼ ë¶„ì„í•œ ìƒì„¸ ìš”ì•½
    """)
